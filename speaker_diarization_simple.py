#!/usr/bin/env python3
"""
Diarisation simple et efficace des locuteurs
Approche directe sans calibration inad√©quate sur √©chantillon
Avec optimisation optionnelle bas√©e sur l'analyse audio du pr√©-traitement
"""

import os
import sys
import argparse
import logging
import time
import json
from pathlib import Path

# Imports pyannote
try:
    from pyannote.audio import Pipeline
    from pyannote.core import Annotation, Segment
    import torch
    PYANNOTE_AVAILABLE = True
except ImportError:
    PYANNOTE_AVAILABLE = False
    print("‚ö†Ô∏è pyannote.audio non disponible. Installation requise : pip install pyannote.audio")

def setup_logging():
    """Configure le syst√®me de journalisation."""
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    
    # Supprimer les handlers existants
    for handler in logger.handlers[:]:
        logger.removeHandler(handler)
    
    console_handler = logging.StreamHandler()
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    
    return logger

def load_audio_analysis(audio_file: str, logger=None):
    """
    Charge l'analyse audio du pr√©-traitement si disponible.
    
    Recherche un fichier JSON d'analyse correspondant au fichier audio.
    Cette approche √©vite de refaire l'analyse et utilise intelligemment
    les r√©sultats du pr√©-traitement.
    """
    audio_path = Path(audio_file)
    
    # Recherche de fichiers d'analyse possibles
    analysis_candidates = [
        audio_path.with_suffix('.json'),  # m√™me nom avec .json
        audio_path.with_name(f"{audio_path.stem}_analysis.json"),  # nom_analysis.json
        audio_path.with_name(f"{audio_path.stem}_enhanced_analysis.json"),  # enhanced_analysis.json
    ]
    
    # Si le fichier est un fichier "enhanced", chercher aussi l'analyse du fichier original
    if "_adaptive_enhanced" in audio_path.stem:
        original_stem = audio_path.stem.replace("_adaptive_enhanced", "")
        analysis_candidates.extend([
            audio_path.with_name(f"{original_stem}.json"),
            audio_path.with_name(f"{original_stem}_analysis.json"),
        ])
    
    for analysis_file in analysis_candidates:
        if analysis_file.exists():
            try:
                with open(analysis_file, 'r') as f:
                    analysis = json.load(f)
                if logger:
                    logger.info(f"üìä Analyse audio charg√©e: {analysis_file}")
                return analysis
            except Exception as e:
                if logger:
                    logger.warning(f"‚ö†Ô∏è Erreur lecture analyse {analysis_file}: {e}")
    
    if logger:
        logger.info("üìä Aucune analyse audio trouv√©e, utilisation des param√®tres par d√©faut")
    return None

def optimize_diarization_parameters(analysis=None, logger=None):
    """
    Optimise les param√®tres de diarisation bas√©s sur l'analyse audio.
    
    Contrairement √† l'approche "adaptative" d√©faillante, cette fonction :
    1. Utilise les param√®tres par d√©faut optimis√©s comme base
    2. Applique des ajustements L√âGERS bas√©s sur l'analyse
    3. Ne change jamais radicalement les param√®tres
    4. Garde toujours des bornes de s√©curit√©
    """
    # Param√®tres par d√©faut optimis√©s (base solide)
    base_params = {
        'clustering_threshold': None,  # Laiss√© √† pyannote
        'min_duration_on': 0.5,       # Dur√©e minimale de parole
        'min_duration_off': 0.1,      # Dur√©e minimale de silence
        'onset': 0.5,                 # Seuil de d√©but de segment
        'offset': 0.5                 # Seuil de fin de segment
    }
    
    if analysis is None:
        if logger:
            logger.info("üéØ Utilisation des param√®tres par d√©faut optimis√©s")
        return base_params
    
    # Ajustements L√âGERS bas√©s sur l'analyse
    optimized_params = base_params.copy()
    
    try:
        # Ajustement bas√© sur la qualit√© d'enregistrement
        recording_quality = analysis.get('recording_quality', 'medium')
        snr_estimate = analysis.get('snr_estimate', 15.0)
        weak_voice_ratio = analysis.get('weak_voice_ratio', 0.3)
        
        if logger:
            logger.info(f"üìä Qualit√© audio: {recording_quality}, SNR: {snr_estimate:.1f}dB, Voix faibles: {weak_voice_ratio*100:.1f}%")
        
        # Ajustement CONSERVATEUR de la dur√©e minimale
        if recording_quality == 'low' or snr_estimate < 10:
            # Audio de mauvaise qualit√© : segments l√©g√®rement plus longs pour √©viter la sur-segmentation
            optimized_params['min_duration_on'] = min(0.8, base_params['min_duration_on'] * 1.3)
            optimized_params['min_duration_off'] = min(0.2, base_params['min_duration_off'] * 1.5)
            if logger:
                logger.info("üîß Ajustement pour audio de faible qualit√©: segments plus longs")
                
        elif recording_quality == 'high' and snr_estimate > 20:
            # Audio de haute qualit√© : segments l√©g√®rement plus courts pour plus de pr√©cision
            optimized_params['min_duration_on'] = max(0.3, base_params['min_duration_on'] * 0.8)
            optimized_params['min_duration_off'] = max(0.05, base_params['min_duration_off'] * 0.8)
            if logger:
                logger.info("üîß Ajustement pour audio de haute qualit√©: segments plus pr√©cis")
        
        # Ajustement CONSERVATEUR des seuils pour voix faibles
        if weak_voice_ratio > 0.5:  # Beaucoup de voix faibles
            # Seuils l√©g√®rement plus sensibles
            optimized_params['onset'] = max(0.3, base_params['onset'] * 0.9)
            optimized_params['offset'] = max(0.3, base_params['offset'] * 0.9)
            if logger:
                logger.info("üîß Ajustement pour voix faibles: seuils plus sensibles")
        
        if logger:
            logger.info("üéØ Param√®tres optimis√©s bas√©s sur l'analyse audio")
            
    except Exception as e:
        if logger:
            logger.warning(f"‚ö†Ô∏è Erreur optimisation param√®tres: {e}, utilisation des param√®tres par d√©faut")
        optimized_params = base_params
    
    return optimized_params

def diarize_audio_simple(audio_file: str, output_file: str = None, logger=None):
    """
    Diarisation simple et directe avec optimisation optionnelle.
    
    Utilise les param√®tres par d√©faut optimis√©s de pyannote avec
    des ajustements l√©gers bas√©s sur l'analyse audio si disponible.
    """
    if not PYANNOTE_AVAILABLE:
        if logger:
            logger.error("‚ùå pyannote.audio non disponible")
        return False
    
    if not os.path.exists(audio_file):
        if logger:
            logger.error(f"‚ùå Fichier {audio_file} non trouv√©")
        return False
    
    # G√©n√©ration automatique du nom de sortie
    if not output_file:
        input_path = Path(audio_file)
        output_file = f"{input_path.stem}_diarization.txt"
    
    if logger:
        logger.info("============================================================")
        logger.info("üé≠ DIARISATION SIMPLE ET EFFICACE")
        logger.info("============================================================")
        logger.info(f"üìÅ Fichier d'entr√©e: {audio_file}")
        logger.info(f"üìÅ Fichier de sortie: {output_file}")
    
    # Chargement de l'analyse audio du pr√©-traitement
    analysis = load_audio_analysis(audio_file, logger)
    
    # Optimisation des param√®tres bas√©e sur l'analyse
    params = optimize_diarization_parameters(analysis, logger)
    
    if logger:
        logger.info("üöÄ D√©but de la diarisation...")
    
    start_time = time.time()
    
    try:
        # Chargement du pipeline pr√©-entra√Æn√© avec param√®tres optimis√©s
        pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization-3.1")
        
        # Application des param√®tres optimis√©s (si diff√©rents des d√©fauts)
        if params['clustering_threshold'] is not None:
            if hasattr(pipeline, '_clustering'):
                pipeline._clustering.threshold = params['clustering_threshold']
        
        if hasattr(pipeline, '_segmentation'):
            if params['min_duration_on'] != 0.5:
                pipeline._segmentation.min_duration_on = params['min_duration_on']
            if params['min_duration_off'] != 0.1:
                pipeline._segmentation.min_duration_off = params['min_duration_off']
            if params['onset'] != 0.5:
                pipeline._segmentation.onset = params['onset']
            if params['offset'] != 0.5:
                pipeline._segmentation.offset = params['offset']
        
        # Application directe sur tout le fichier
        diarization = pipeline(audio_file)
        
        # Extraction des informations
        speakers = set()
        segments = []
        total_speech_time = 0.0
        
        for turn, _, speaker in diarization.itertracks(yield_label=True):
            speakers.add(speaker)
            segments.append({
                'start': turn.start,
                'end': turn.end,
                'duration': turn.end - turn.start,
                'speaker': speaker
            })
            total_speech_time += turn.end - turn.start
        
        # Tri par temps de d√©but
        segments.sort(key=lambda x: x['start'])
        
        # Sauvegarde des r√©sultats
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("DIARISATION DES LOCUTEURS\n")
            f.write("=" * 50 + "\n\n")
            
            if analysis:
                f.write("OPTIMISATION BAS√âE SUR L'ANALYSE AUDIO:\n")
                f.write(f"‚Ä¢ Qualit√© d'enregistrement: {analysis.get('recording_quality', 'N/A')}\n")
                f.write(f"‚Ä¢ SNR estim√©: {analysis.get('snr_estimate', 'N/A'):.1f} dB\n")
                f.write(f"‚Ä¢ Ratio voix faibles: {analysis.get('weak_voice_ratio', 'N/A')*100:.1f}%\n")
                f.write("\nPARAM√àTRES APPLIQU√âS:\n")
                f.write(f"‚Ä¢ Dur√©e min. parole: {params['min_duration_on']:.2f}s\n")
                f.write(f"‚Ä¢ Dur√©e min. silence: {params['min_duration_off']:.2f}s\n")
                f.write(f"‚Ä¢ Seuil d√©but: {params['onset']:.2f}\n")
                f.write(f"‚Ä¢ Seuil fin: {params['offset']:.2f}\n\n")
            
            f.write(f"Nombre de locuteurs d√©tect√©s: {len(speakers)}\n")
            f.write(f"Nombre de segments: {len(segments)}\n")
            f.write(f"Temps de parole total: {total_speech_time:.1f}s\n\n")
            
            f.write("SEGMENTS PAR LOCUTEUR:\n")
            f.write("-" * 30 + "\n")
            
            for speaker in sorted(speakers):
                speaker_segments = [s for s in segments if s['speaker'] == speaker]
                speaker_time = sum(s['duration'] for s in speaker_segments)
                f.write(f"\n{speaker}: {len(speaker_segments)} segments, {speaker_time:.1f}s\n")
                
                for seg in speaker_segments:
                    f.write(f"  {seg['start']:7.1f}s - {seg['end']:7.1f}s ({seg['duration']:5.1f}s)\n")
            
            f.write("\nCHRONOLOGIE COMPL√àTE:\n")
            f.write("-" * 25 + "\n")
            
            for seg in segments:
                f.write(f"{seg['start']:7.1f}s - {seg['end']:7.1f}s | {seg['speaker']} ({seg['duration']:5.1f}s)\n")
        
        processing_time = time.time() - start_time
        
        if logger:
            logger.info("üéâ DIARISATION TERMIN√âE")
            logger.info("-" * 30)
            logger.info(f"üé≠ Locuteurs d√©tect√©s: {len(speakers)}")
            logger.info(f"üìä Segments totaux: {len(segments)}")
            logger.info(f"üó£Ô∏è Temps de parole: {total_speech_time:.1f}s")
            logger.info(f"‚è±Ô∏è Temps de traitement: {processing_time:.1f}s")
            logger.info(f"üíæ R√©sultats sauv√©s: {output_file}")
            
            # Statistiques par locuteur
            for speaker in sorted(speakers):
                speaker_segments = [s for s in segments if s['speaker'] == speaker]
                speaker_time = sum(s['duration'] for s in speaker_segments)
                percentage = (speaker_time / total_speech_time) * 100
                logger.info(f"   {speaker}: {speaker_time:.1f}s ({percentage:.1f}%)")
        
        return True
        
    except Exception as e:
        if logger:
            logger.error(f"‚ùå Erreur lors de la diarisation: {str(e)}")
        return False

def main():
    """Point d'entr√©e principal."""
    parser = argparse.ArgumentParser(description="Diarisation simple des locuteurs avec optimisation optionnelle")
    parser.add_argument("audio_file", help="Fichier audio √† traiter")
    parser.add_argument("-o", "--output", help="Fichier de sortie (optionnel)")
    parser.add_argument("-v", "--verbose", action="store_true", help="Mode verbeux")
    
    args = parser.parse_args()
    
    logger = setup_logging()
    
    success = diarize_audio_simple(
        audio_file=args.audio_file,
        output_file=args.output,
        logger=logger
    )
    
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main() 